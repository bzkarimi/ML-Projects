{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blossoming Date Prediction\n",
    "In this exercise we will predict the flowering date of cherry blossoms at Hirosaki Park in Hirosaki City, Aomori Prefecture, Japan using a Nueral Network by analyzing the temperature data and previous flowering information (from 1997 - 2019)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature</th>\n",
       "      <th>flower_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997/1/1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997/1/2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997/1/3</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997/1/4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997/1/5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  temperature flower_status\n",
       "0  1997/1/1          2.9           NaN\n",
       "1  1997/1/2          2.2           NaN\n",
       "2  1997/1/3         -1.6           NaN\n",
       "3  1997/1/4          0.2           NaN\n",
       "4  1997/1/5         -0.4           NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_blossom = pd.read_csv('hirosaki_temp_cherry_bloom.csv')\n",
    "data_blossom.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8400 entries, 0 to 8399\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           8400 non-null   object \n",
      " 1   temperature    8400 non-null   float64\n",
      " 2   flower_status  69 non-null     object \n",
      " 3   year           8400 non-null   object \n",
      " 4   month          8400 non-null   object \n",
      " 5   day            8400 non-null   object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 393.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature</th>\n",
       "      <th>flower_status</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997/1/1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997/1/2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997/1/3</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997/1/4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997/1/5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date  temperature flower_status  year month day\n",
       "0  1997/1/1          2.9           NaN  1997     1   1\n",
       "1  1997/1/2          2.2           NaN  1997     1   2\n",
       "2  1997/1/3         -1.6           NaN  1997     1   3\n",
       "3  1997/1/4          0.2           NaN  1997     1   4\n",
       "4  1997/1/5         -0.4           NaN  1997     1   5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blossom = pd.DataFrame(data_blossom)\n",
    "\n",
    "# Adding 3 new cols: split date into year,month,day\n",
    "dateList = df_blossom['date'].str.split('/', expand=True)\n",
    "df_blossom['year'], df_blossom['month'], df_blossom['day'] = dateList[0], dateList[1], dateList[2]\n",
    "df_blossom.info()\n",
    "df_blossom.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'bloom', 'full', 'scatter'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blossom['flower_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year month day  temperature  flower_status\n",
      "0     1997     1   1          2.9              0\n",
      "1     1997     1   2          2.2              0\n",
      "2     1997     1   3         -1.6              0\n",
      "3     1997     1   4          0.2              0\n",
      "4     1997     1   5         -0.4              0\n",
      "...    ...   ...  ..          ...            ...\n",
      "8395  2019    12  27         -0.2              3\n",
      "8396  2019    12  28         -1.3              3\n",
      "8397  2019    12  29         -0.6              3\n",
      "8398  2019    12  30          1.8              3\n",
      "8399  2019    12  31         -0.2              3\n",
      "\n",
      "[8400 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "new_df_blossom = []\n",
    "\n",
    "# 0:Before blooming, 1:Bloom, 2:Full bloom, 3:Scatter\n",
    "# Note that we consider the status of flower to be 0 at the begining of the year\n",
    "# and we fill in all NaN as below:\n",
    "# NaN NaN NaN 1 NaN NaN 2 NaN NaN NaN 3 NaN NaN -->\n",
    "# 0 0 0 1 1 1 2 2 2 2 3 3 3\n",
    "\n",
    "for i in range(len(df_blossom)):\n",
    "    if ((df_blossom['month'][i] == '1') & (df_blossom['day'][i] == '1')):\n",
    "        status = 0\n",
    "    elif(df_blossom['flower_status'][i] == 'bloom'):\n",
    "        status = 1\n",
    "    elif(df_blossom['flower_status'][i] == 'full'):\n",
    "        status = 2\n",
    "    elif(df_blossom['flower_status'][i] == 'scatter'):\n",
    "        status = 3\n",
    "    \n",
    "    new_df_blossom.append({'year':df_blossom['year'][i],\n",
    "                           'month':df_blossom['month'][i],\n",
    "                           'day':df_blossom['day'][i], \n",
    "                           'temperature':df_blossom['temperature'][i],\n",
    "                           'flower_status':status})\n",
    "\n",
    "new_df_blossom = pd.DataFrame(new_df_blossom)\n",
    "print(new_df_blossom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_blossom['flower_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>temperature</th>\n",
       "      <th>flower_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month day  temperature  flower_status\n",
       "0  1997     1   1          2.9              0\n",
       "1  1997     1   2          2.2              0\n",
       "2  1997     1   3         -1.6              0\n",
       "3  1997     1   4          0.2              0\n",
       "4  1997     1   5         -0.4              0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_blossom.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8400 entries, 0 to 8399\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   year           8400 non-null   object \n",
      " 1   month          8400 non-null   object \n",
      " 2   day            8400 non-null   object \n",
      " 3   temperature    8400 non-null   float64\n",
      " 4   flower_status  8400 non-null   int64  \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 328.2+ KB\n"
     ]
    }
   ],
   "source": [
    "new_df_blossom.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    5648\n",
       "0    2537\n",
       "1     127\n",
       "2      88\n",
       "Name: flower_status, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_blossom.flower_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since most of our flower_status data is 0 or 3 we focus on the months when it is more likely to have blossoms \n",
    "# March, April, May\n",
    "new_df_blossom = new_df_blossom.loc[(new_df_blossom['month'] == '3') | \n",
    "                                    (new_df_blossom['month'] == '4') |\n",
    "                                    (new_df_blossom['month'] == '5') ]\n",
    "new_df_blossom.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Split Data to Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = new_df_blossom.drop('flower_status', axis = 1)\n",
    "y = new_df_blossom['flower_status']\n",
    "\n",
    "X = X.astype('float64')\n",
    "y = y.astype('int32')\n",
    "\n",
    "features = MinMaxScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2116 entries, 0 to 2115\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   year         2116 non-null   float64\n",
      " 1   month        2116 non-null   float64\n",
      " 2   day          2116 non-null   float64\n",
      " 3   temperature  2116 non-null   float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 66.2 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    353\n",
       "3    223\n",
       "1     35\n",
       "2     24\n",
       "Name: flower_status, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Our Model (Neural Network - MLPClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.35057868\n",
      "Iteration 2, loss = 1.23333781\n",
      "Iteration 3, loss = 1.13863914\n",
      "Iteration 4, loss = 1.06236393\n",
      "Iteration 5, loss = 0.99978717\n",
      "Iteration 6, loss = 0.94761075\n",
      "Iteration 7, loss = 0.90471196\n",
      "Iteration 8, loss = 0.86529212\n",
      "Iteration 9, loss = 0.83154925\n",
      "Iteration 10, loss = 0.80056069\n",
      "Iteration 11, loss = 0.77185861\n",
      "Iteration 12, loss = 0.74422368\n",
      "Iteration 13, loss = 0.71869487\n",
      "Iteration 14, loss = 0.69507559\n",
      "Iteration 15, loss = 0.67318989\n",
      "Iteration 16, loss = 0.65334377\n",
      "Iteration 17, loss = 0.63448556\n",
      "Iteration 18, loss = 0.61731953\n",
      "Iteration 19, loss = 0.60148103\n",
      "Iteration 20, loss = 0.58669883\n",
      "Iteration 21, loss = 0.57307026\n",
      "Iteration 22, loss = 0.56023860\n",
      "Iteration 23, loss = 0.54823722\n",
      "Iteration 24, loss = 0.53699665\n",
      "Iteration 25, loss = 0.52619678\n",
      "Iteration 26, loss = 0.51604581\n",
      "Iteration 27, loss = 0.50643704\n",
      "Iteration 28, loss = 0.49739774\n",
      "Iteration 29, loss = 0.48857926\n",
      "Iteration 30, loss = 0.48047863\n",
      "Iteration 31, loss = 0.47267915\n",
      "Iteration 32, loss = 0.46526493\n",
      "Iteration 33, loss = 0.45795907\n",
      "Iteration 34, loss = 0.45093560\n",
      "Iteration 35, loss = 0.44416630\n",
      "Iteration 36, loss = 0.43761744\n",
      "Iteration 37, loss = 0.43148325\n",
      "Iteration 38, loss = 0.42537475\n",
      "Iteration 39, loss = 0.41957684\n",
      "Iteration 40, loss = 0.41433772\n",
      "Iteration 41, loss = 0.40888387\n",
      "Iteration 42, loss = 0.40378620\n",
      "Iteration 43, loss = 0.39893750\n",
      "Iteration 44, loss = 0.39448232\n",
      "Iteration 45, loss = 0.39016707\n",
      "Iteration 46, loss = 0.38563883\n",
      "Iteration 47, loss = 0.38164022\n",
      "Iteration 48, loss = 0.37840905\n",
      "Iteration 49, loss = 0.37416274\n",
      "Iteration 50, loss = 0.37060410\n",
      "Iteration 51, loss = 0.36703623\n",
      "Iteration 52, loss = 0.36377904\n",
      "Iteration 53, loss = 0.36059548\n",
      "Iteration 54, loss = 0.35738626\n",
      "Iteration 55, loss = 0.35441410\n",
      "Iteration 56, loss = 0.35208596\n",
      "Iteration 57, loss = 0.34920964\n",
      "Iteration 58, loss = 0.34649062\n",
      "Iteration 59, loss = 0.34392359\n",
      "Iteration 60, loss = 0.34142734\n",
      "Iteration 61, loss = 0.33919333\n",
      "Iteration 62, loss = 0.33712987\n",
      "Iteration 63, loss = 0.33468378\n",
      "Iteration 64, loss = 0.33272340\n",
      "Iteration 65, loss = 0.33092762\n",
      "Iteration 66, loss = 0.32899942\n",
      "Iteration 67, loss = 0.32749736\n",
      "Iteration 68, loss = 0.32535795\n",
      "Iteration 69, loss = 0.32354084\n",
      "Iteration 70, loss = 0.32245138\n",
      "Iteration 71, loss = 0.32028775\n",
      "Iteration 72, loss = 0.31887320\n",
      "Iteration 73, loss = 0.31721533\n",
      "Iteration 74, loss = 0.31594014\n",
      "Iteration 75, loss = 0.31430925\n",
      "Iteration 76, loss = 0.31298109\n",
      "Iteration 77, loss = 0.31164184\n",
      "Iteration 78, loss = 0.30999768\n",
      "Iteration 79, loss = 0.30906171\n",
      "Iteration 80, loss = 0.30757814\n",
      "Iteration 81, loss = 0.30660741\n",
      "Iteration 82, loss = 0.30549943\n",
      "Iteration 83, loss = 0.30404480\n",
      "Iteration 84, loss = 0.30317094\n",
      "Iteration 85, loss = 0.30192167\n",
      "Iteration 86, loss = 0.30087608\n",
      "Iteration 87, loss = 0.29979396\n",
      "Iteration 88, loss = 0.29892597\n",
      "Iteration 89, loss = 0.29823436\n",
      "Iteration 90, loss = 0.29747700\n",
      "Iteration 91, loss = 0.29637148\n",
      "Iteration 92, loss = 0.29592393\n",
      "Iteration 93, loss = 0.29460979\n",
      "Iteration 94, loss = 0.29379030\n",
      "Iteration 95, loss = 0.29278102\n",
      "Iteration 96, loss = 0.29260102\n",
      "Iteration 97, loss = 0.29149935\n",
      "Iteration 98, loss = 0.29031509\n",
      "Iteration 99, loss = 0.28967287\n",
      "Iteration 100, loss = 0.28914070\n",
      "Iteration 101, loss = 0.28898718\n",
      "Iteration 102, loss = 0.28774790\n",
      "Iteration 103, loss = 0.28667370\n",
      "Iteration 104, loss = 0.28594184\n",
      "Iteration 105, loss = 0.28538334\n",
      "Iteration 106, loss = 0.28464930\n",
      "Iteration 107, loss = 0.28420743\n",
      "Iteration 108, loss = 0.28327552\n",
      "Iteration 109, loss = 0.28256321\n",
      "Iteration 110, loss = 0.28225177\n",
      "Iteration 111, loss = 0.28150846\n",
      "Iteration 112, loss = 0.28082726\n",
      "Iteration 113, loss = 0.28048895\n",
      "Iteration 114, loss = 0.27970414\n",
      "Iteration 115, loss = 0.27917344\n",
      "Iteration 116, loss = 0.27860041\n",
      "Iteration 117, loss = 0.27840687\n",
      "Iteration 118, loss = 0.27759007\n",
      "Iteration 119, loss = 0.27723740\n",
      "Iteration 120, loss = 0.27667802\n",
      "Iteration 121, loss = 0.27617146\n",
      "Iteration 122, loss = 0.27596060\n",
      "Iteration 123, loss = 0.27504063\n",
      "Iteration 124, loss = 0.27495938\n",
      "Iteration 125, loss = 0.27434093\n",
      "Iteration 126, loss = 0.27389281\n",
      "Iteration 127, loss = 0.27344930\n",
      "Iteration 128, loss = 0.27291245\n",
      "Iteration 129, loss = 0.27257188\n",
      "Iteration 130, loss = 0.27202817\n",
      "Iteration 131, loss = 0.27174577\n",
      "Iteration 132, loss = 0.27154853\n",
      "Iteration 133, loss = 0.27097296\n",
      "Iteration 134, loss = 0.27076438\n",
      "Iteration 135, loss = 0.27007160\n",
      "Iteration 136, loss = 0.26997451\n",
      "Iteration 137, loss = 0.26931420\n",
      "Iteration 138, loss = 0.26909872\n",
      "Iteration 139, loss = 0.26871171\n",
      "Iteration 140, loss = 0.26871003\n",
      "Iteration 141, loss = 0.26821959\n",
      "Iteration 142, loss = 0.26802680\n",
      "Iteration 143, loss = 0.26762364\n",
      "Iteration 144, loss = 0.26726192\n",
      "Iteration 145, loss = 0.26648736\n",
      "Iteration 146, loss = 0.26699309\n",
      "Iteration 147, loss = 0.26679889\n",
      "Iteration 148, loss = 0.26588542\n",
      "Iteration 149, loss = 0.26577671\n",
      "Iteration 150, loss = 0.26531277\n",
      "Iteration 151, loss = 0.26507547\n",
      "Iteration 152, loss = 0.26456350\n",
      "Iteration 153, loss = 0.26441380\n",
      "Iteration 154, loss = 0.26401346\n",
      "Iteration 155, loss = 0.26386877\n",
      "Iteration 156, loss = 0.26362078\n",
      "Iteration 157, loss = 0.26308367\n",
      "Iteration 158, loss = 0.26306322\n",
      "Iteration 159, loss = 0.26279917\n",
      "Iteration 160, loss = 0.26248707\n",
      "Iteration 161, loss = 0.26236074\n",
      "Iteration 162, loss = 0.26236431\n",
      "Iteration 163, loss = 0.26179413\n",
      "Iteration 164, loss = 0.26144835\n",
      "Iteration 165, loss = 0.26123946\n",
      "Iteration 166, loss = 0.26110398\n",
      "Iteration 167, loss = 0.26077662\n",
      "Iteration 168, loss = 0.26113779\n",
      "Iteration 169, loss = 0.26066910\n",
      "Iteration 170, loss = 0.26028032\n",
      "Iteration 171, loss = 0.26004058\n",
      "Iteration 172, loss = 0.26020418\n",
      "Iteration 173, loss = 0.25951505\n",
      "Iteration 174, loss = 0.25958358\n",
      "Iteration 175, loss = 0.25937823\n",
      "Iteration 176, loss = 0.25949028\n",
      "Iteration 177, loss = 0.25904999\n",
      "Iteration 178, loss = 0.25863301\n",
      "Iteration 179, loss = 0.25870568\n",
      "Iteration 180, loss = 0.25820895\n",
      "Iteration 181, loss = 0.25831166\n",
      "Iteration 182, loss = 0.25794988\n",
      "Iteration 183, loss = 0.25767753\n",
      "Iteration 184, loss = 0.25752898\n",
      "Iteration 185, loss = 0.25717327\n",
      "Iteration 186, loss = 0.25711718\n",
      "Iteration 187, loss = 0.25711412\n",
      "Iteration 188, loss = 0.25685955\n",
      "Iteration 189, loss = 0.25695052\n",
      "Iteration 190, loss = 0.25673291\n",
      "Iteration 191, loss = 0.25638609\n",
      "Iteration 192, loss = 0.25644189\n",
      "Iteration 193, loss = 0.25612303\n",
      "Iteration 194, loss = 0.25603065\n",
      "Iteration 195, loss = 0.25577389\n",
      "Iteration 196, loss = 0.25576712\n",
      "Iteration 197, loss = 0.25553610\n",
      "Iteration 198, loss = 0.25534724\n",
      "Iteration 199, loss = 0.25541673\n",
      "Iteration 200, loss = 0.25557314\n",
      "Iteration 201, loss = 0.25473233\n",
      "Iteration 202, loss = 0.25454367\n",
      "Iteration 203, loss = 0.25453497\n",
      "Iteration 204, loss = 0.25442911\n",
      "Iteration 205, loss = 0.25447439\n",
      "Iteration 206, loss = 0.25473734\n",
      "Iteration 207, loss = 0.25471565\n",
      "Iteration 208, loss = 0.25417620\n",
      "Iteration 209, loss = 0.25389529\n",
      "Iteration 210, loss = 0.25395329\n",
      "Iteration 211, loss = 0.25365723\n",
      "Iteration 212, loss = 0.25362052\n",
      "Iteration 213, loss = 0.25347657\n",
      "Iteration 214, loss = 0.25331244\n",
      "Iteration 215, loss = 0.25343286\n",
      "Iteration 216, loss = 0.25322050\n",
      "Iteration 217, loss = 0.25323017\n",
      "Iteration 218, loss = 0.25296200\n",
      "Iteration 219, loss = 0.25296733\n",
      "Iteration 220, loss = 0.25255653\n",
      "Iteration 221, loss = 0.25242551\n",
      "Iteration 222, loss = 0.25237616\n",
      "Iteration 223, loss = 0.25212881\n",
      "Iteration 224, loss = 0.25216444\n",
      "Iteration 225, loss = 0.25223600\n",
      "Iteration 226, loss = 0.25222748\n",
      "Iteration 227, loss = 0.25189783\n",
      "Iteration 228, loss = 0.25231510\n",
      "Iteration 229, loss = 0.25164133\n",
      "Iteration 230, loss = 0.25183892\n",
      "Iteration 231, loss = 0.25138467\n",
      "Iteration 232, loss = 0.25175620\n",
      "Iteration 233, loss = 0.25164405\n",
      "Iteration 234, loss = 0.25131352\n",
      "Iteration 235, loss = 0.25123772\n",
      "Iteration 236, loss = 0.25134337\n",
      "Iteration 237, loss = 0.25122486\n",
      "Iteration 238, loss = 0.25143313\n",
      "Iteration 239, loss = 0.25115766\n",
      "Iteration 240, loss = 0.25086389\n",
      "Iteration 241, loss = 0.25087488\n",
      "Iteration 242, loss = 0.25079806\n",
      "Iteration 243, loss = 0.25086179\n",
      "Iteration 244, loss = 0.25061839\n",
      "Iteration 245, loss = 0.25057116\n",
      "Iteration 246, loss = 0.25055215\n",
      "Iteration 247, loss = 0.25018746\n",
      "Iteration 248, loss = 0.25038352\n",
      "Iteration 249, loss = 0.25057323\n",
      "Iteration 250, loss = 0.25048211\n",
      "Iteration 251, loss = 0.24987045\n",
      "Iteration 252, loss = 0.25024844\n",
      "Iteration 253, loss = 0.24988540\n",
      "Iteration 254, loss = 0.24989082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 255, loss = 0.24996536\n",
      "Iteration 256, loss = 0.25043904\n",
      "Iteration 257, loss = 0.25041149\n",
      "Iteration 258, loss = 0.25013648\n",
      "Iteration 259, loss = 0.24998335\n",
      "Iteration 260, loss = 0.24930259\n",
      "Iteration 261, loss = 0.24944699\n",
      "Iteration 262, loss = 0.24991756\n",
      "Iteration 263, loss = 0.24952486\n",
      "Iteration 264, loss = 0.24953532\n",
      "Iteration 265, loss = 0.24924048\n",
      "Iteration 266, loss = 0.24919683\n",
      "Iteration 267, loss = 0.24936531\n",
      "Iteration 268, loss = 0.24935665\n",
      "Iteration 269, loss = 0.24996325\n",
      "Iteration 270, loss = 0.24850983\n",
      "Iteration 271, loss = 0.24929849\n",
      "Iteration 272, loss = 0.24879606\n",
      "Iteration 273, loss = 0.24904276\n",
      "Iteration 274, loss = 0.24867559\n",
      "Iteration 275, loss = 0.24854848\n",
      "Iteration 276, loss = 0.24860837\n",
      "Iteration 277, loss = 0.24825079\n",
      "Iteration 278, loss = 0.24845594\n",
      "Iteration 279, loss = 0.24832549\n",
      "Iteration 280, loss = 0.24832675\n",
      "Iteration 281, loss = 0.24830462\n",
      "Iteration 282, loss = 0.24883532\n",
      "Iteration 283, loss = 0.24805637\n",
      "Iteration 284, loss = 0.24842766\n",
      "Iteration 285, loss = 0.24860333\n",
      "Iteration 286, loss = 0.24797082\n",
      "Iteration 287, loss = 0.24814348\n",
      "Iteration 288, loss = 0.24795995\n",
      "Iteration 289, loss = 0.24795085\n",
      "Iteration 290, loss = 0.24839881\n",
      "Iteration 291, loss = 0.24805941\n",
      "Iteration 292, loss = 0.24864926\n",
      "Iteration 293, loss = 0.24818708\n",
      "Iteration 294, loss = 0.24785723\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=1000, verbose=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import neural_network\n",
    "\n",
    "clf = neural_network.MLPClassifier(max_iter=1000,       # default:200\n",
    "                                   activation=\"relu\",   # default:\"relu\"\n",
    "                                   solver=\"adam\",       # default:\"adam\"\n",
    "                                   alpha=0.0001,        # default:0.0001\n",
    "                                   verbose=True,        # default:False\n",
    "                                   early_stopping=False)# default:False\n",
    "# fit our model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Plot the Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, predict)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       353\n",
      "           1       0.33      0.29      0.31        35\n",
      "           2       0.25      0.12      0.17        24\n",
      "           3       0.90      0.98      0.94       223\n",
      "\n",
      "    accuracy                           0.90       635\n",
      "   macro avg       0.61      0.59      0.59       635\n",
      "weighted avg       0.88      0.90      0.89       635\n",
      "\n",
      "accuracy : 0.89764\n"
     ]
    }
   ],
   "source": [
    "classReport = classification_report(y_test, predict)\n",
    "print(classReport)\n",
    "\n",
    "score = accuracy_score(y_test, predict)\n",
    "print('accuracy :', '{:.5f}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
